# Autonomous AI Agent - Deployment Guide

## ğŸš€ Docker Deployment

### Local Docker Build & Run

```bash
# Build the Docker image
docker build -t autonomous-ai-agent .

# Run the container locally
docker run -p 8501:8501 \
  -e GEMINI_API_KEY="your-api-key-here" \
  autonomous-ai-agent
```

### Test locally
```bash
# Access the app
open http://localhost:8501
```

## ğŸŒ Render Deployment

### Prerequisites
1. GitHub repository with your code
2. Render account (free tier available)
3. Gemini API key

### Deployment Steps

1. **Push to GitHub**
   ```bash
   git add .
   git commit -m "Add Docker deployment configuration"
   git push origin main
   ```

2. **Connect to Render**
   - Go to [render.com](https://render.com)
   - Sign up/Login with GitHub
   - Click "New +" â†’ "Web Service"
   - Connect your GitHub repository

3. **Configure Service**
   - **Name**: `autonomous-ai-agent`
   - **Environment**: `Docker`
   - **Branch**: `main`
   - **Dockerfile Path**: `./Dockerfile`
   - **Plan**: `Starter` (free)

4. **Set Environment Variables**
   ```
   GEMINI_API_KEY = your-gemini-api-key-here
   GEMINI_MODEL = gemini-2.0-flash
   GEMINI_TEMPERATURE = 0.7
   GEMINI_MAX_TOKENS = 1000
   LOG_LEVEL = INFO
   ```

5. **Deploy**
   - Click "Create Web Service"
   - Wait for build to complete (~5-10 minutes)
   - Your app will be available at: `https://your-app-name.onrender.com`

## ğŸ“ Production File Structure

```
AI-Agent/
â”‚
â”œâ”€â”€ Dockerfile              # Docker configuration
â”œâ”€â”€ .dockerignore           # Docker ignore file
â”œâ”€â”€ render.yaml             # Render deployment config
â”œâ”€â”€ requirements-prod.txt   # Production dependencies
â”œâ”€â”€ config.py               # Environment-based config
â”œâ”€â”€ web_ui.py               # Main Streamlit app
â”œâ”€â”€ run_ui.py               # Launcher script
â”‚
â”œâ”€â”€ agents/                 # Agent implementation
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ gemini_agent.py
â”‚
â””â”€â”€ utils/                  # Utilities
    â”œâ”€â”€ __init__.py
    â””â”€â”€ logger.py
```

## ğŸ”§ Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `GEMINI_API_KEY` | Google Gemini API key | Required |
| `GEMINI_MODEL` | Gemini model to use | `gemini-2.0-flash` |
| `GEMINI_TEMPERATURE` | Model temperature | `0.7` |
| `GEMINI_MAX_TOKENS` | Max response tokens | `1000` |
| `LOG_LEVEL` | Logging level | `INFO` |

## ğŸ¯ Production Features

- âœ… **Dockerized**: Containerized for consistent deployment
- âœ… **Environment-based**: Secure configuration management
- âœ… **Health Checks**: Built-in health monitoring
- âœ… **Optimized**: Minimal dependencies for faster builds
- âœ… **Scalable**: Ready for horizontal scaling
- âœ… **Secure**: API keys via environment variables

## ğŸš¨ Important Notes

1. **API Key Security**: Never commit API keys to Git
2. **Free Tier Limits**: Render free tier has sleep after inactivity
3. **Build Time**: First build may take 5-10 minutes
4. **Cold Starts**: Free tier may have cold start delays

## ğŸ” Troubleshooting

### Build Issues
```bash
# Check Docker build locally
docker build -t test-agent .

# Check logs
docker logs <container-id>
```

### Runtime Issues
- Check Render logs in dashboard
- Verify environment variables are set
- Ensure API key is valid

### Performance
- Upgrade to paid plan for better performance
- Consider caching for frequent requests
- Monitor resource usage in Render dashboard

---

**Ready for production deployment! ğŸš€**
